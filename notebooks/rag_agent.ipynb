{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MiniConda\\envs\\rocket\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from rocket_rag.utils import *\n",
    "from rocket_rag.node_indexing import *\n",
    "from rocket_rag.vector_store import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = '40kg'\n",
    "if_files_dict = parse_files(main_directory=INFERENCE_DIR)\n",
    "if_ts_files = if_files_dict[load]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random inference sample: ../data/inference/40kg\\spalling7\\spalling7_40_1_4.csv\n",
      "ROCKET features shape: (1, 20000)\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(42)\n",
    "\n",
    "rand_idx = np.random.randint(0, len(if_ts_files))\n",
    "if_ts_filename = if_ts_files[rand_idx]\n",
    "print(f'Random inference sample: {if_ts_filename}')\n",
    "if_rocket_feature = fit_transform([if_ts_filename],\n",
    "                                    field='current',\n",
    "                                    smooth=True,\n",
    "                                    smooth_ws=15,\n",
    "                                    tolist=False,\n",
    "                                    verbo=False)\n",
    "print(f'ROCKET features shape: {if_rocket_feature.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-18 12:09:31.203\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mrocket_rag.node_indexing\u001b[0m:\u001b[36mload_node_indexing\u001b[0m:\u001b[36m98\u001b[0m - \u001b[34m\u001b[1mLoading all nodes...\u001b[0m\n",
      "\u001b[32m2024-03-18 12:09:31.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrocket_rag.node_indexing\u001b[0m:\u001b[36mload_node_indexing\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mAll nodes are loaded.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "node_indexer = NodeIndexer()\n",
    "nodes = node_indexer.load_node_indexing(f'../store/nodes_{load}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = VectorStore()\n",
    "vector_store.add(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3.1987850822921007', '3.772884271423856', '3.989529120390713', '4.239072661571159', '4.822921558144848']\n",
      "['spalling7_40_1_5', 'spalling7_40_9_3', 'spalling7_40_10_4', 'spalling7_40_7_3', 'spalling7_40_10_2']\n"
     ]
    }
   ],
   "source": [
    "s, ids = vector_store.knn_query(if_rocket_feature, k=5)\n",
    "print(s)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the fault diagnosis reuslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from rocket_rag.prompts import fault_diagnosis_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = \"../config/configs.json\"\n",
    "with open(CONFIG_FILE) as f:\n",
    "    config = json.load(f)\n",
    "    GOOGLE_API_KEY = config[\"google_api_key\"]\n",
    "    GOOGLE_CSE_ID = config[\"google_cse_id\"]\n",
    "    OPENAI_API_KEY = config[\"openai_api_key\"]\n",
    "    GPT_MODEL = config[\"gpt_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat with an intelligent assistant in your terminal\n",
    "from openai import OpenAI\n",
    "\n",
    "LOCAL = False\n",
    "\n",
    "# Point to the local server or use remote OpenAI GPT API\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"not-needed\") if LOCAL else OpenAI(api_key=OPENAI_API_KEY)\n",
    "model = \"local-model\" if LOCAL else GPT_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval results: ['spalling7_40_1_5', 'spalling7_40_9_3', 'spalling7_40_10_4', 'spalling7_40_7_3', 'spalling7_40_10_2']\n",
      "Diagnosis results:\n",
      "Refined fault type1: Obvious fault in spalling\n",
      "Inference evidence: [spalling7_40_1_5 with 3.1987850822921007, spalling7_40_9_3 with 3.772884271423856, spalling7_40_10_4 with 3.989529120390713, spalling7_40_7_3 with 4.239072661571159, spalling7_40_10_2 with 4.822921558144848]\n",
      "Description of the Fault: This state indicates that the ball-screw mechanism within the actuator has significant surface damage. This level of spalling affects the actuator's smoothness and efficiency severely. The presence of such a fault suggests that the actuator's performance and longevity are compromised, necessitating immediate attention and likely repair or replacement to restore normal operation."
     ]
    }
   ],
   "source": [
    "history = [\n",
    "    {\"role\": \"system\", \"content\": fault_diagnosis_prompt.sys_prompt},\n",
    "    {\"role\": \"user\", \"content\": fault_diagnosis_prompt.user_prompt.format(res=str(ids), score=s)},\n",
    "]\n",
    "\n",
    "completions = client.chat.completions.create(\n",
    "    model=model, # this field is currently unused\n",
    "    messages=history,\n",
    "    temperature=0.1,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "new_message = {\"role\": \"assistant\", \"content\": \"\"}\n",
    "\n",
    "for chunk in completions:\n",
    "    if chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "        new_message[\"content\"] += chunk.choices[0].delta.content\n",
    "\n",
    "history.append(new_message)\n",
    "fault_diagnosis_res = new_message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use multi-query generation for query parsing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rocket_rag.prompts import multi_queries_gen_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to repair spalling damage in ball-screw actuators\n",
      "best practices for preventing spalling in linear actuators\n",
      "replacement options for ball-screw actuators with spalling damage\n",
      "diagnosing spalling in linear actuators for effective maintenance\n",
      "cost-effective solutions for spalling damage in actuator mechanisms"
     ]
    }
   ],
   "source": [
    "mq_messages = [\n",
    "    {\"role\": \"system\", \"content\": multi_queries_gen_prompt.sys_prompt},\n",
    "    {\"role\": \"user\", \"content\": multi_queries_gen_prompt.user_prompt.format(res=fault_diagnosis_res, num=5)},\n",
    "]\n",
    "            \n",
    "completions = client.chat.completions.create(\n",
    "    model=model, # this field is currently unused\n",
    "    messages=mq_messages,\n",
    "    temperature=0.1,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "new_message = {\"role\": \"assistant\", \"content\": \"\"}\n",
    "\n",
    "for chunk in completions:\n",
    "    if chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "        new_message[\"content\"] += chunk.choices[0].delta.content\n",
    "\n",
    "history.append(new_message)\n",
    "multi_queries_gen = new_message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def formalize_query(query: str):\n",
    "    \"\"\"Preprocess the query for the vector store query\n",
    "    \n",
    "    Remove some symbols including '-', '\"', '.' and indexing numbers or patterns like 1. 2. 3. ...\n",
    "    \"\"\"\n",
    "    query = query.strip().replace('\"', '').replace('. ', '')\n",
    "    pattern = re.compile(r'[-0-9]+|\\d+\\. ')\n",
    "    result = pattern.sub('', query)\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how to repair spalling damage in ballscrew actuators',\n",
       " 'best practices for preventing spalling in linear actuators',\n",
       " 'replacement options for ballscrew actuators with spalling damage',\n",
       " 'diagnosing spalling in linear actuators for effective maintenance',\n",
       " 'costeffective solutions for spalling damage in actuator mechanisms']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_queries = [formalize_query(query) for query in multi_queries_gen.split('\\n')]\n",
    "generated_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use external tools for query search for decision-support\n",
    "Here use Google chrome web browser for a proof-of-concept validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"This includes reconditioning the actuator's ball screw, repairing and/or replacing worn or damaged internal components, replacing cover bands, and replacing all\\xa0...\", 'Jan 7, 2010 ... This service bulletin also gives instructions to remove/replace and repair the Horizontal Stabilizer Trim Actuator if a damaged. Ballscrew or\\xa0...', 'Often premature flaking or abnormal damage may lead to machine failure. Cause of the problem may include careless handling, excessive misalignment, insufficient\\xa0...', 'for Duff-Norton translating ball screw actuators. ... Do not allow actuator travel to go beyond cata- log closed height of actuator or serious damage to internal\\xa0...', 'Damage Condition, Possible Causes, Countermeasures. The raceways of the screw shaft and ball nut and/or the surface of the ball peel off like scales because\\xa0...', 'Check ball nut threads for damage and replace if necessary. 7. Check retaining wire location. Some are free to rotate to other part of nut when the return.', 'Troubleshooting - Damage by Type - Flaking occurs when small pieces of bearing material are split off from the smooth surface of the raceway or rolling\\xa0...', 'When time is of the essence, our emergency repair team will restore your damaged ... Spalling / Flaking Brinelling Vibration ... Thread-Craft, Inc. is a\\xa0...', 'inch screws, are cost effective and easy to install, maintain and repair. ... Check for metal fragments that may cause damage and could be an indication of broken\\xa0...', 'Structural failures such as excess of wear, cracking, backlash or spalling, malfunctions such as ball return channel jamming or seizure and lubricant\\xa0...']\n"
     ]
    }
   ],
   "source": [
    "def call_google(query: str, **kwargs):\n",
    "    \"\"\" Call the google chrome for searching online \"\"\"\n",
    "    \n",
    "    service = build(serviceName=\"customsearch\", \n",
    "                    version=\"v1\", \n",
    "                    developerKey=GOOGLE_API_KEY,\n",
    "                    static_discovery=False)\n",
    "    res = service.cse().list(q=query, cx=GOOGLE_CSE_ID, **kwargs).execute()\n",
    "    res_items = res[\"items\"]\n",
    "    res_snippets = [r['snippet'] for r in res_items]\n",
    "    return str(res_snippets)\n",
    "\n",
    "# A quick validation for the call_google\n",
    "print(call_google(query=generated_queries[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"call_google\",\n",
    "            \"description\": \"Call the google chrome web browser to search online based on a given query\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The query string for searching online\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_tools = {\"call_google\": call_google}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use ReAct Prompting to call the external functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rocket_rag.prompts import react_prompt\n",
    "# from colorama import Fore, Back, Style\n",
    "\n",
    "# # regular expression regex patterns\n",
    "# action_re = re.compile('^Action: (\\w+): (.*)$')\n",
    "# answer_re = re.compile(\"Answer: \")\n",
    "# answers = []\n",
    "\n",
    "# chrome_messages = [\n",
    "#     {\"role\": \"system\", \"content\": react_prompt.sys_prompt},\n",
    "#     {\"role\": \"user\", \"content\": react_prompt.user_prompt.format(query=generated_queries[0])},\n",
    "# ]\n",
    "\n",
    "# while True:\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=model,\n",
    "#         messages=chrome_messages,\n",
    "#     )\n",
    "    \n",
    "#     # Get the response from the GPT and add it as a part of memory\n",
    "#     response_msg = response.choices[0].message.content\n",
    "#     history.append({\"role\": \"assistant\", \"content\": response_msg})\n",
    "    \n",
    "#     # If the respionse contains the keyword \"Answer: \", then return\n",
    "#     if answer_re.search(response_msg):\n",
    "#         print(Fore.YELLOW + response.choices[0].message.content)\n",
    "#         print(Style.RESET_ALL)\n",
    "#         answers.append(answer_re.search(response_msg).group(1))\n",
    "#         break\n",
    "    \n",
    "#     # Print the thinking process\n",
    "#     print(Fore.GREEN + response_msg)\n",
    "#     print(Style.RESET_ALL)\n",
    "\n",
    "#     # Take actions\n",
    "#     actions = [action_re.match(a) for a in response_msg.split(\"\\n\") if action_re.match(a)]\n",
    "#     if actions:\n",
    "#         action, action_input = actions[0].groups()\n",
    "#         try:\n",
    "#             print(Fore.CYAN + f\" -- running {action} {action_input}\")\n",
    "#             print(Style.RESET_ALL)\n",
    "#             # Apply available tools for the function execution\n",
    "#             obervation = available_tools[action](action_input) \n",
    "#             print(Fore.BLUE + f\"Observation: {obervation}\")\n",
    "#             print(Style.RESET_ALL)\n",
    "#             history.append({\"role\": \"user\", \"content\": \"Observation: \" + obervation})\n",
    "#         except:\n",
    "#             raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GPT function calling to use external tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[32m2024-03-18 12:33:53.585\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1mProcessing 1/5 query...\u001b[0m\n",
      "\u001b[32m2024-03-18 12:33:55.613\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[34m\u001b[1m{'query': 'how to repair spalling damage in ballscrew actuators'}\u001b[0m\n",
      " 20%|██        | 1/5 [00:23<01:35, 23.87s/it]\u001b[32m2024-03-18 12:34:17.457\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1mProcessing 2/5 query...\u001b[0m\n",
      "\u001b[32m2024-03-18 12:34:19.458\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[34m\u001b[1m{'query': 'best practices for preventing spalling in linear actuators'}\u001b[0m\n",
      " 40%|████      | 2/5 [00:53<01:21, 27.12s/it]\u001b[32m2024-03-18 12:34:46.853\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1mProcessing 3/5 query...\u001b[0m\n",
      "\u001b[32m2024-03-18 12:34:49.054\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[34m\u001b[1m{'query': 'replacement options for ballscrew actuators with spalling damage'}\u001b[0m\n",
      " 60%|██████    | 3/5 [01:28<01:02, 31.01s/it]\u001b[32m2024-03-18 12:35:22.490\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1mProcessing 4/5 query...\u001b[0m\n",
      "\u001b[32m2024-03-18 12:35:24.804\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[34m\u001b[1m{'query': 'diagnosing spalling in linear actuators for effective maintenance'}\u001b[0m\n",
      " 80%|████████  | 4/5 [01:50<00:27, 27.30s/it]\u001b[32m2024-03-18 12:35:44.110\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1mProcessing 5/5 query...\u001b[0m\n",
      "\u001b[32m2024-03-18 12:35:46.089\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[34m\u001b[1m{'query': 'cost-effective solutions for spalling damage in actuator mechanisms'}\u001b[0m\n",
      "100%|██████████| 5/5 [02:15<00:00, 27.07s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "answers = []\n",
    "for i in tqdm(range(len(generated_queries))):\n",
    "    loguru.logger.debug(f'Processing {i+1}/{len(generated_queries)} query...')\n",
    "\n",
    "    gpt_tool_call_messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful chatbot that can use web browser to offer reliable searching results to human beings.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Search for the following query using Google web browser: {generated_queries[i]}\"}\n",
    "    ]\n",
    "\n",
    "    first_response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=gpt_tool_call_messages,\n",
    "        tools=tools,\n",
    "    )\n",
    "    # print(first_response)\n",
    "    \n",
    "    gpt_tool_call_messages.append(first_response.choices[0].message)\n",
    "    tool_calls = first_response.choices[0].message.tool_calls\n",
    "    if tool_calls:\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_tools[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            loguru.logger.debug(function_args)\n",
    "            function_response = function_to_call(**function_args)\n",
    "\n",
    "            gpt_tool_call_messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    second_response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=gpt_tool_call_messages,\n",
    "        tools=tools,\n",
    "    )\n",
    "    # print(second_response)\n",
    "    \n",
    "    answers.append(second_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering all searching results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "from openai import AsyncClient\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncclient = AsyncClient(api_key=OPENAI_API_KEY)\n",
    "\n",
    "async def async_combined_responses(query_responses: List[str], sys_prompt: str, num_children=3, debug=False):\n",
    "    \"\"\"Async version of combining responses from different nodes\"\"\"\n",
    "\n",
    "    node_batch_prompts = []\n",
    "    for idx in range(0, len(query_responses), num_children):\n",
    "        node_batch = query_responses[idx:idx+num_children]\n",
    "        node_batch_text = \"\\n\\n\".join([node for node in node_batch])\n",
    "\n",
    "        temp_prompt = f\"\"\" \\\n",
    "        Context information is below: \n",
    "        {node_batch_text}\n",
    "        Given the context information and not prior knowledge, summarize and present the result with detailed descriptions.\n",
    "        Combined result: \\\n",
    "        \"\"\"\n",
    "\n",
    "        node_batch_prompts.append(temp_prompt)\n",
    "    \n",
    "    tasks = [asyncclient.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": tp}\n",
    "        ]) for tp in node_batch_prompts\n",
    "    ]\n",
    "\n",
    "    combined_responses = await asyncio.gather(*tasks)\n",
    "    new_texts = [r.choices[0].message.content for r in combined_responses]\n",
    "\n",
    "    if len(new_texts) == 1:\n",
    "        loguru.logger.info(f\"Combined all responses to one. Done\")\n",
    "        return new_texts[0]\n",
    "    else:\n",
    "        loguru.logger.info(f\"Combined into {len(new_texts)} responses, keep combining\")\n",
    "        if debug:\n",
    "            loguru.logger.info(new_texts)\n",
    "        return await async_combined_responses(new_texts, sys_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-18 12:37:16.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36masync_combined_responses\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mCombined into 2 responses, keep combining\u001b[0m\n",
      "\u001b[32m2024-03-18 12:38:12.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36masync_combined_responses\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mCombined all responses to one. Done\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "combined_result_sys_prompt = f\"You are a helpful assistant that can summarize and extract useful information from give text as follow.\"\n",
    "combined_result = await async_combined_responses(answers, combined_result_sys_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all contents into one markdown file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_expr = [str(i+1) + '. ' + generated_queries[i] + \"\\\\\" for i in range(len(generated_queries))]\n",
    "queries_expr = \"\\n\".join(queries_expr)\n",
    "anwsers_expr = ('\\n'.join(answers)).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = \"*FAULT DIAGNOSIS REPORT\\n\\n\" + fault_diagnosis_res + \"\\n\\n\"\\\n",
    "\"Searching for: \\n\" + queries_expr + \"\\n\\n\"\n",
    "suggestions = \"Maintenance suggestions: \\n\" + combined_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = '../logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-18 12:38:27.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mSaved report to ../logs/fault-diagnosis2024-03-18-12-38-27.md\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dt = datetime.datetime.today().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "save_filename = 'fault-diagnosis-' + dt + '.md'\n",
    "save_filepath = os.path.join(LOG_DIR, save_filename)\n",
    "\n",
    "try:\n",
    "    with open(save_filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(report)\n",
    "        for i in range(len(anwsers_expr)):\n",
    "            f.write(f\"{anwsers_expr[i]} \\\\\")\n",
    "        f.write(suggestions)\n",
    "    loguru.logger.info(f\"Saved report to {save_filepath}\")\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Failed to save report to {save_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
